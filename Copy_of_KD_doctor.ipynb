{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithin2700000/Project-2/blob/main/Copy_of_KD_doctor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zQcpGKe807Kz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub0ug14ME84B",
        "outputId": "dffb1b67-d6e1-461d-f83d-ffcae05d21fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import gensim.downloader as api\n",
        "print(list(api.info()['models'].keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1ag9LyHCBY",
        "outputId": "4ae6684e-b9b7-47aa-d42d-60f3b36ac046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wv = api.load('word2vec-google-news-300')"
      ],
      "metadata": {
        "id": "csvbodW5HKxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Reshape\n",
        "\n",
        "# Read the Excel file\n",
        "dataset = pd.read_excel('/content/Final doctor (3).xlsx')\n",
        "\n",
        "# Access the data\n",
        "# For example, you can print the first few rows\n",
        "print(dataset.head())\n",
        "\n",
        "# Assuming you have the dataset in two separate lists: reviews and ratings\n",
        "reviews = dataset['review']\n",
        "knowledge = dataset['knowledge']\n",
        "Helpful = dataset['Helpful']\n",
        "staff = dataset['staff']\n",
        "\n",
        "# Normalize the ratings to a range of 0 to 4 using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "knowledge_encoded = label_encoder.fit_transform(knowledge)  # Encode knowledge ratings from 0 to 4\n",
        "helpful_encoded = label_encoder.fit_transform(Helpful)  # Encode Helpful ratings from 0 to 4\n",
        "staff_encoded = label_encoder.fit_transform(staff)  # Encode staff ratings from 0 to 4\n",
        "\n",
        "# Combine the encoded arrays into a single target array\n",
        "target = np.stack((knowledge_encoded, helpful_encoded, staff_encoded), axis=1)\n",
        "\n",
        "# Perform text preprocessing\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(reviews)  # Build vocabulary from the reviews\n",
        "\n",
        "# Convert text reviews to sequences of indices\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "\n",
        "# Pad sequences to have the same length\n",
        "max_seq_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length)\n",
        "# Load the Google Word2Vec model\n",
        "#path_to_model = r\"C:\\Users\\adith\\Downloads\\word2vec_model.bin\"\n",
        "#word2vec_model = KeyedVectors.load_word2vec_format(output, binary=True)\n",
        "\n",
        "# Create an embedding matrix\n",
        "embedding_dim = 300  # Dimension of the Google Word2Vec model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if word in wv:\n",
        "        embedding_matrix[index] = wv[word]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, target, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfnJnj4ZUcr5",
        "outputId": "fef4b36c-0172-4d9e-b5f8-e124e0d2ebb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  knowledge  Helpful  \\\n",
            "0  b'Fabulous doctor! Dr. Ranen really takes his ...          5        5   \n",
            "1  b'Wonderful doctor! Very punctual, but takes h...          5        5   \n",
            "2  b\"Great caring Doctor always there for you.Won...          5        5   \n",
            "3  b'Dr. Foreman is great!!!! I believe he would ...          5        5   \n",
            "4  b'Dr. Foreman I highly respect. He has done ma...          5        5   \n",
            "\n",
            "   staff  \n",
            "0      5  \n",
            "1      5  \n",
            "2      5  \n",
            "3      5  \n",
            "4      5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB1UabVmYlZv",
        "outputId": "2bcc3c0d-4f55-473c-806b-fdb8706e23f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37322, 1678)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "0B2WtxtDLxra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXrfMgg8-PKq",
        "outputId": "274327de-8546-4137-c02a-8dc717725bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('/content/drive/MyDrive/model_doctor.h5')"
      ],
      "metadata": {
        "id": "olGrlsNvKLkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avDoIKYZPeZ0",
        "outputId": "b925a2e4-7f86-4669-a425-eea56f5c21e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1678, 300)         14235600  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1674, 128)         192128    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 837, 128)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 834, 128)          65664     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 417, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 413, 128)          82048     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 206, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 206, 128)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 26368)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               6750464   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3, 5)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,360,735\n",
            "Trainable params: 7,125,135\n",
            "Non-trainable params: 14,235,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXh_QMaseu_c",
        "outputId": "77df1c78-bae0-4472-e009-9146464de472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "292/292 [==============================] - 11s 13ms/step - loss: 0.7917 - accuracy: 0.8848\n",
            "Test Loss: 0.7917\n",
            "Test Accuracy: 0.8848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "tf.random.set_seed(3)"
      ],
      "metadata": {
        "id": "JEq1mroBQXux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "            )\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        #student_predictions = tf.reshape(student_predictions, [-1, 3])\n",
        "\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "YNrd-YxLQKNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Flatten, Dense, Reshape\n",
        "\n",
        "# Define the parameters\n",
        "\n",
        "\n",
        "# Create the student model\n",
        "model1= Sequential()\n",
        "model1.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
        "\n",
        "# Embedding layer\n",
        "\n",
        "# Convolutional layers\n",
        "filters = 64\n",
        "model1.add(Conv1D(filters, 5, activation='relu'))\n",
        "model1.add(MaxPooling1D())\n",
        "model1.add(Conv1D(filters, 4, activation='relu'))\n",
        "model1.add(MaxPooling1D())\n",
        "model1.add(Conv1D(filters, 5, activation='relu'))\n",
        "model1.add(MaxPooling1D())\n",
        "model1.add(Dropout(0.2))\n",
        "model1.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dropout(0.5))\n",
        "model1.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "output_units = 3\n",
        "num_classes = 5\n",
        "model1.add(Dense(output_units * num_classes, activation='softmax'))\n",
        "model1.add(Reshape((output_units, num_classes)))\n",
        "\n",
        "# Compile the model\n",
        "#model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "lQPXNrhkQ34C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1zWqZphXw9r",
        "outputId": "f94f2aee-e798-4687-8c73-cd02d1b663d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1678, 300)         14235600  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 1674, 64)          96064     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 837, 64)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 834, 64)           16448     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 417, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 413, 64)           20544     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 206, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 206, 64)           0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 13184)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1687680   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 15)                975       \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3, 5)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,065,567\n",
            "Trainable params: 1,829,967\n",
            "Non-trainable params: 14,235,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, Dense, Reshape, GlobalMaxPooling1D"
      ],
      "metadata": {
        "id": "OUm7HrAedhVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = Sequential()\n",
        "student_model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_seq_length, trainable=False))\n",
        "student_model.add(Conv1D(128, 3, activation='relu'))\n",
        "student_model.add(GlobalMaxPooling1D())\n",
        "student_model.add(Dense(256, activation='relu'))\n",
        "student_model.add(Dense(output_units * num_classes, activation='softmax'))\n",
        "student_model.add(Reshape((output_units, num_classes)))"
      ],
      "metadata": {
        "id": "xweUF8Z-dN2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOtdmOn2dkHV",
        "outputId": "79e83488-97ee-46ac-ee29-ed2d90eab7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1678, 300)         14235600  \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1676, 128)         115328    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 15)                3855      \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 3, 5)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,387,807\n",
            "Trainable params: 152,207\n",
            "Non-trainable params: 14,235,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student_model, teacher=model)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=40,\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "distiller.fit(X_train, y_train, epochs=75)\n",
        "print(\"---Testing Accuracy---\")\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKM2AaY4ZaBi",
        "outputId": "918aab48-7e92-44b1-e5f9-0dbd8a0a0b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "1167/1167 [==============================] - 35s 26ms/step - sparse_categorical_accuracy: 0.8704 - student_loss: 1.3956 - distillation_loss: 3.7914e-06\n",
            "Epoch 2/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3932 - distillation_loss: 3.2681e-06\n",
            "Epoch 3/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3921 - distillation_loss: 3.5961e-06\n",
            "Epoch 4/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3905 - distillation_loss: 4.0055e-06\n",
            "Epoch 5/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3889 - distillation_loss: 4.0827e-06\n",
            "Epoch 6/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3875 - distillation_loss: 3.9922e-06\n",
            "Epoch 7/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3866 - distillation_loss: 3.7900e-06\n",
            "Epoch 8/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3859 - distillation_loss: 3.6953e-06\n",
            "Epoch 9/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3855 - distillation_loss: 3.6288e-06\n",
            "Epoch 10/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8718 - student_loss: 1.3852 - distillation_loss: 3.5900e-06\n",
            "Epoch 11/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.8772 - student_loss: 1.3835 - distillation_loss: 3.8071e-06\n",
            "Epoch 12/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9055 - student_loss: 1.3750 - distillation_loss: 5.1224e-06\n",
            "Epoch 13/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9117 - student_loss: 1.3712 - distillation_loss: 5.0653e-06\n",
            "Epoch 14/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9143 - student_loss: 1.3697 - distillation_loss: 4.9764e-06\n",
            "Epoch 15/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9164 - student_loss: 1.3686 - distillation_loss: 4.8800e-06\n",
            "Epoch 16/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9163 - student_loss: 1.3682 - distillation_loss: 4.9125e-06\n",
            "Epoch 17/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9172 - student_loss: 1.3677 - distillation_loss: 4.7846e-06\n",
            "Epoch 18/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9180 - student_loss: 1.3670 - distillation_loss: 4.6589e-06\n",
            "Epoch 19/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9181 - student_loss: 1.3667 - distillation_loss: 4.6499e-06\n",
            "Epoch 20/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9183 - student_loss: 1.3666 - distillation_loss: 4.6478e-06\n",
            "Epoch 21/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9188 - student_loss: 1.3662 - distillation_loss: 4.5423e-06\n",
            "Epoch 22/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9187 - student_loss: 1.3661 - distillation_loss: 4.6090e-06\n",
            "Epoch 23/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9190 - student_loss: 1.3658 - distillation_loss: 4.5234e-06\n",
            "Epoch 24/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9196 - student_loss: 1.3655 - distillation_loss: 4.4551e-06\n",
            "Epoch 25/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9194 - student_loss: 1.3653 - distillation_loss: 4.4591e-06\n",
            "Epoch 26/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9188 - student_loss: 1.3654 - distillation_loss: 4.4977e-06\n",
            "Epoch 27/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9194 - student_loss: 1.3650 - distillation_loss: 4.4431e-06\n",
            "Epoch 28/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9194 - student_loss: 1.3650 - distillation_loss: 4.3643e-06\n",
            "Epoch 29/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9199 - student_loss: 1.3647 - distillation_loss: 4.3473e-06\n",
            "Epoch 30/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9199 - student_loss: 1.3647 - distillation_loss: 4.3558e-06\n",
            "Epoch 31/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9197 - student_loss: 1.3647 - distillation_loss: 4.3125e-06\n",
            "Epoch 32/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9194 - student_loss: 1.3647 - distillation_loss: 4.3326e-06\n",
            "Epoch 33/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9198 - student_loss: 1.3647 - distillation_loss: 4.3208e-06\n",
            "Epoch 34/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9199 - student_loss: 1.3643 - distillation_loss: 4.2471e-06\n",
            "Epoch 35/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9201 - student_loss: 1.3643 - distillation_loss: 4.2439e-06\n",
            "Epoch 36/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9201 - student_loss: 1.3643 - distillation_loss: 4.2582e-06\n",
            "Epoch 37/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9198 - student_loss: 1.3645 - distillation_loss: 4.2607e-06\n",
            "Epoch 38/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9202 - student_loss: 1.3641 - distillation_loss: 4.2480e-06\n",
            "Epoch 39/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9204 - student_loss: 1.3641 - distillation_loss: 4.1327e-06\n",
            "Epoch 40/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9200 - student_loss: 1.3642 - distillation_loss: 4.1984e-06\n",
            "Epoch 41/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9203 - student_loss: 1.3639 - distillation_loss: 4.1613e-06\n",
            "Epoch 42/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9204 - student_loss: 1.3639 - distillation_loss: 4.1587e-06\n",
            "Epoch 43/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9203 - student_loss: 1.3640 - distillation_loss: 4.1606e-06\n",
            "Epoch 44/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9200 - student_loss: 1.3640 - distillation_loss: 4.1685e-06\n",
            "Epoch 45/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9203 - student_loss: 1.3639 - distillation_loss: 4.0901e-06\n",
            "Epoch 46/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9202 - student_loss: 1.3639 - distillation_loss: 4.0981e-06\n",
            "Epoch 47/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9201 - student_loss: 1.3639 - distillation_loss: 4.0831e-06\n",
            "Epoch 48/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9205 - student_loss: 1.3636 - distillation_loss: 4.0872e-06\n",
            "Epoch 49/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9206 - student_loss: 1.3635 - distillation_loss: 4.0633e-06\n",
            "Epoch 50/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9205 - student_loss: 1.3635 - distillation_loss: 4.0130e-06\n",
            "Epoch 51/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9207 - student_loss: 1.3637 - distillation_loss: 4.0332e-06\n",
            "Epoch 52/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9208 - student_loss: 1.3635 - distillation_loss: 4.0034e-06\n",
            "Epoch 53/75\n",
            "1167/1167 [==============================] - 29s 24ms/step - sparse_categorical_accuracy: 0.9209 - student_loss: 1.3636 - distillation_loss: 4.0680e-06\n",
            "Epoch 54/75\n",
            "1167/1167 [==============================] - 29s 24ms/step - sparse_categorical_accuracy: 0.9212 - student_loss: 1.3634 - distillation_loss: 4.0176e-06\n",
            "Epoch 55/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9211 - student_loss: 1.3634 - distillation_loss: 3.9938e-06\n",
            "Epoch 56/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9211 - student_loss: 1.3633 - distillation_loss: 3.9954e-06\n",
            "Epoch 57/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9212 - student_loss: 1.3633 - distillation_loss: 4.0614e-06\n",
            "Epoch 58/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9215 - student_loss: 1.3632 - distillation_loss: 4.0156e-06\n",
            "Epoch 59/75\n",
            "1167/1167 [==============================] - 29s 24ms/step - sparse_categorical_accuracy: 0.9211 - student_loss: 1.3635 - distillation_loss: 4.0804e-06\n",
            "Epoch 60/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9214 - student_loss: 1.3632 - distillation_loss: 4.0143e-06\n",
            "Epoch 61/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9218 - student_loss: 1.3631 - distillation_loss: 4.0589e-06\n",
            "Epoch 62/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9220 - student_loss: 1.3631 - distillation_loss: 4.0476e-06\n",
            "Epoch 63/75\n",
            "1167/1167 [==============================] - 29s 24ms/step - sparse_categorical_accuracy: 0.9220 - student_loss: 1.3629 - distillation_loss: 4.0859e-06\n",
            "Epoch 64/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9221 - student_loss: 1.3628 - distillation_loss: 4.1158e-06\n",
            "Epoch 65/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9223 - student_loss: 1.3627 - distillation_loss: 4.1056e-06\n",
            "Epoch 66/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9226 - student_loss: 1.3625 - distillation_loss: 4.1079e-06\n",
            "Epoch 67/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9227 - student_loss: 1.3624 - distillation_loss: 4.1253e-06\n",
            "Epoch 68/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9231 - student_loss: 1.3620 - distillation_loss: 4.0986e-06\n",
            "Epoch 69/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9231 - student_loss: 1.3619 - distillation_loss: 4.1362e-06\n",
            "Epoch 70/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9232 - student_loss: 1.3618 - distillation_loss: 4.1601e-06\n",
            "Epoch 71/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9235 - student_loss: 1.3616 - distillation_loss: 4.0757e-06\n",
            "Epoch 72/75\n",
            "1167/1167 [==============================] - 29s 25ms/step - sparse_categorical_accuracy: 0.9234 - student_loss: 1.3616 - distillation_loss: 4.0351e-06\n",
            "Epoch 73/75\n",
            "1167/1167 [==============================] - 29s 24ms/step - sparse_categorical_accuracy: 0.9235 - student_loss: 1.3616 - distillation_loss: 4.1180e-06\n",
            "Epoch 74/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9236 - student_loss: 1.3615 - distillation_loss: 4.1419e-06\n",
            "Epoch 75/75\n",
            "1167/1167 [==============================] - 28s 24ms/step - sparse_categorical_accuracy: 0.9238 - student_loss: 1.3612 - distillation_loss: 4.0812e-06\n",
            "---Testing Accuracy---\n",
            "292/292 [==============================] - 2s 8ms/step - sparse_categorical_accuracy: 0.9075 - student_loss: 1.3814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9074768424034119, 1.3708158731460571]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "2HpZ7OpxZsVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293a51cf-baff-46f9-d3db-864314ff0ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.26.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "tmq-JbofiMsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "GI3_dz4KiXBZ",
        "outputId": "affdda2e-10aa-4d4c-8c5b-c36965e1f639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnithin-270103\u001b[0m (\u001b[33mnithinsairam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230626_093426-iw0ezko6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nithinsairam/uncategorized/runs/iw0ezko6' target=\"_blank\">hardy-firefly-5</a></strong> to <a href='https://wandb.ai/nithinsairam/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nithinsairam/uncategorized' target=\"_blank\">https://wandb.ai/nithinsairam/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nithinsairam/uncategorized/runs/iw0ezko6' target=\"_blank\">https://wandb.ai/nithinsairam/uncategorized/runs/iw0ezko6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nithinsairam/uncategorized/runs/iw0ezko6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6200ada7a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}